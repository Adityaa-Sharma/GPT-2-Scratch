{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"combine_poems.txt\",encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "# want to remove integers from the text\n",
    "import re\n",
    "text = re.sub(r'\\d+', '', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text:  2151083\n"
     ]
    }
   ],
   "source": [
    "print(\"length of text: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique characters:  94\n",
      "characters:  \n",
      " !\"&'()*,-./:;>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^`abcdefghijklmnopqrstuvwxyz{}~£³´ÆÔäæèéëïöŒ–—‘’‹\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "print(\"number of unique characters: \", vocab_size)\n",
    "print(\"characters: \", ''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [54, 51, 58, 58, 61]\n",
      "decoded:  hello\n"
     ]
    }
   ],
   "source": [
    "# stoi={ch:i for i,ch in enumerate(chars)}\n",
    "stoi={}\n",
    "for i,ch in enumerate(chars):\n",
    "    stoi[ch]=i\n",
    "    \n",
    "itos={}\n",
    "for i,ch in enumerate(chars):\n",
    "    itos[i]=ch\n",
    "# itos={i:ch for i,ch in enumerate(chars)}\n",
    "encode=lambda x: [stoi[ch] for ch in x]\n",
    "decode=lambda x: ''.join([itos[i] for i in x])\n",
    "\n",
    "print(\"encoded: \", encode(\"hello\"))\n",
    "print(\"decoded: \", decode(encode(\"hello\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data:  torch.Size([2151083])\n",
      "first 10 characters:  tensor([ 0, 32, 61, 51, 59,  1, 13,  1, 17,  1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data=torch.tensor(encode(text),dtype=torch.long)\n",
    "print(\"shape of the data: \", data.shape)\n",
    "print(\"first 10 characters: \", data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(0.9*len(data))\n",
    "train_data, val_data=data[:n], data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 32, 61, 51, 59,  1, 13,  1, 17])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can not train the model on the entire data at once\n",
    "block_size=8\n",
    "train_data[:block_size+1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 32, 61, 51, 59,  1, 13,  1])\n",
      "tensor([32, 61, 51, 59,  1, 13,  1, 17])\n"
     ]
    }
   ],
   "source": [
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) -> tensor(32)\n",
      "tensor([ 0, 32]) -> tensor(61)\n",
      "tensor([ 0, 32, 61]) -> tensor(51)\n",
      "tensor([ 0, 32, 61, 51]) -> tensor(59)\n",
      "tensor([ 0, 32, 61, 51, 59]) -> tensor(1)\n",
      "tensor([ 0, 32, 61, 51, 59,  1]) -> tensor(13)\n",
      "tensor([ 0, 32, 61, 51, 59,  1, 13]) -> tensor(1)\n",
      "tensor([ 0, 32, 61, 51, 59,  1, 13,  1]) -> tensor(17)\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t] # y is already one ahead of x\n",
    "    print(context, \"->\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "torch.Size([4, 8])\n",
      "tensor([[59, 14,  1, 71, 61, 60,  1,  5],\n",
      "        [55, 60, 66, 61,  1, 52, 58, 47],\n",
      "        [ 1, 69, 55, 66, 54,  1, 54, 55],\n",
      "        [54, 51, 71,  1, 65, 51, 51,  1]])\n",
      "target:\n",
      "torch.Size([4, 8])\n",
      "tensor([[14,  1, 71, 61, 60,  1,  5, 65],\n",
      "        [60, 66, 61,  1, 52, 58, 47, 57],\n",
      "        [69, 55, 66, 54,  1, 54, 55, 65],\n",
      "        [51, 71,  1, 65, 51, 51,  1, 71]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size=4# how many independent streams of data we want to process in parallel\n",
    "block_size=8 # what is the sequence length of each batch,or max contxt length of the prediction\n",
    "\n",
    "def get_batch(split):\n",
    "    data=train_data if split== 'train' else val_data\n",
    "    ix=torch.randint(0,len(data)-block_size,(batch_size,))\n",
    "    # print(\"printing ix: \", ix)\n",
    "\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "x,y=get_batch('train')\n",
    "print(\"input:\")\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "print(\"target:\")\n",
    "print(y.shape)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[808595]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement the bigram model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__() ## call the parent class constructor\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
    "        \n",
    "    def forward(self, idx,targets=None):\n",
    "        logits=self.token_embedding_table(idx) # B T C\n",
    "        # print(\"logits\", logits)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            \n",
    "            # print(\"shape of logits: \", logits.shape)\n",
    "            # but pytorch expects B C T\n",
    "            B,T,C=logits.shape\n",
    "        \n",
    "            logits=logits.view(B*T,C)\n",
    "            # print(\"shape of logits after view: \", logits.shape)\n",
    "            # print(\"shape of targets: \", targets.shape)\n",
    "            targets=targets.view(B*T)\n",
    "            # print(\"shape of targets: \", targets.shape)\n",
    "            loss=F.cross_entropy(logits,targets)\n",
    "        return logits,loss\n",
    "        \n",
    "\n",
    "    def generate(self,idx,max_new_token):\n",
    "        for _ in range(max_new_token):\n",
    "            logits,loss=self(idx)\n",
    "            logits=logits[:,-1,:] #only getting the (B,C)\n",
    "            probs=F.softmax(logits,dim=-1) # B,C\n",
    "            idx_next=torch.multinomial(probs,1) # B,1\n",
    "            # print(\"idx: \", idx)\n",
    "            idx=torch.cat([idx,idx_next],dim=1)\n",
    "            \n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input torch.Size([4, 8])\n",
      "torch.Size([32, 94])\n",
      "tensor(4.7964, grad_fn=<NllLossBackward0>)\n",
      "idx:  tensor([[0]])\n",
      "\n",
      "³\"\"L?/:W,)`XW’~Œswë[- dæèé{pP—G*A[M*æejQ–£DVèx‹äoŒMRr?dD–T`£kWD/ær) jfU};z–tqdbDzi‘vbDZoiga^éKw&^,{a\n"
     ]
    }
   ],
   "source": [
    "m=Bigram(vocab_size)\n",
    "print(\"shape of input\", x.shape)\n",
    "logit,loss=m(x,y)\n",
    "print(logit.shape)\n",
    "print(loss)\n",
    "\n",
    "idx=torch.zeros((1,1),dtype=torch.long)\n",
    "print(\"idx: \", idx)\n",
    "print(decode(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_token=100)[0].tolist())) # [0] to unlock the first tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.516305685043335\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "optimizer=torch.optim.Adam(m.parameters(),lr=1e-3)\n",
    "batch_size=32\n",
    "for steps in range(1000):\n",
    "    xb,yb=get_batch('train')\n",
    "    logits,loss=m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " \"Slacoorowoubure pleve\n",
      "\n",
      "Thalis de wisand  omatht;PYï‘ht g pls n athe wor\n",
      "\n",
      "\n",
      "\n",
      "Arrratchj,  ndars\n",
      "\n",
      "Au\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_token=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gpt tokenization \n",
    "import tiktoken\n",
    "encode=tiktoken.get_encoding('gpt2')\n",
    "encode.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## self attention\n",
    "import torch\n",
    "torch\n",
    "B,T,C=4,8,2\n",
    "x=torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow=torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev=x[b,:t+1] # (t,C)\n",
    "        xbow[b,t]=torch.mean(xprev,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3646, -0.3629],\n",
       "        [ 0.3509,  0.0096],\n",
       "        [-0.3019,  0.8705],\n",
       "        [ 0.5402,  0.3682],\n",
       "        [ 0.0183, -0.0471],\n",
       "        [-0.1879, -0.2887],\n",
       "        [ 2.0596, -1.2550],\n",
       "        [ 0.6449, -0.8334]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3646, -0.3629],\n",
       "        [ 0.8578, -0.1767],\n",
       "        [ 0.4712,  0.1724],\n",
       "        [ 0.4885,  0.2214],\n",
       "        [ 0.3944,  0.1677],\n",
       "        [ 0.2974,  0.0916],\n",
       "        [ 0.5491, -0.1008],\n",
       "        [ 0.5611, -0.1923]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0] # vertical average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "c=\n",
      "tensor([[5.0000, 7.0000],\n",
      "        [3.5000, 3.5000],\n",
      "        [4.0000, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "a=torch.tril(torch.ones(3,3))\n",
    "a=a/torch.sum(a,dim=1,keepdim=True)\n",
    "b=torch.randint(0,10,(3,2)).float()\n",
    "c=a@b\n",
    "\n",
    "print('a=')\n",
    "print(a)\n",
    "print('b=') \n",
    "print(b)\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3646, -0.3629],\n",
       "        [ 0.8578, -0.1767],\n",
       "        [ 0.4712,  0.1724],\n",
       "        [ 0.4885,  0.2214],\n",
       "        [ 0.3944,  0.1677],\n",
       "        [ 0.2974,  0.0916],\n",
       "        [ 0.5491, -0.1008],\n",
       "        [ 0.5611, -0.1923]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totril=torch.tril(torch.ones(T,T))\n",
    "wei=torch.zeros((T,T))\n",
    "wei=wei.masked_fill(totril==0,float('-inf'))\n",
    "wei=F.softmax(wei,dim=1)\n",
    "xbow=wei@x\n",
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self attention improved version\n",
    "torch.manual_seed(1337)\n",
    "B,T,C=4,8,32\n",
    "x=torch.randn(B,T,C)\n",
    "\n",
    "head_size=16\n",
    "key=nn.Linear(C,head_size,bias=False)\n",
    "query=nn.Linear(C,head_size,bias=False)\n",
    "value=nn.Linear(C,head_size,bias=False)\n",
    "k=key(x) # B T 16\n",
    "q=query(x) # B T 16\n",
    "wei=q @ k.transpose(-2,-1) # (B,T,16) @ (B,16,T) ----> B T T\n",
    "\n",
    "tril=torch.tril(torch.ones(T,T))\n",
    "# wei=torch.zeros((T,T))\n",
    "wei=wei.masked_fill(tril==0,float('-inf'))\n",
    "wei=F.softmax(wei,dim=-1)\n",
    "\n",
    "v=value(x) # B T 16\n",
    "out=wei@v\n",
    "\n",
    "out.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def scrape_poems( url):\n",
    "    # Base URL\n",
    "    \n",
    "    # Headers to mimic a browser request\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make the request\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        \n",
    "        # Create BeautifulSoup object\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the poem list container\n",
    "        poem_list = soup.find('ul', class_='list-poems nuevolist orderprimero')\n",
    "        \n",
    "        if not poem_list:\n",
    "            print(\"Could not find the poem list container\")\n",
    "            return\n",
    "        \n",
    "        # Get all poem links\n",
    "        poem_links = poem_links = poem_list.find_all('a', rel='nofollow')\n",
    "        \n",
    "        # Create/open a text file to store the poems\n",
    "        with open('combine_poems1.txt', 'w', encoding='utf-8') as file:\n",
    "            \n",
    "            # Iterate through each poem link\n",
    "            for i, link in enumerate(poem_links, 1):\n",
    "                poem_url = link['href']\n",
    "                if not poem_url.startswith('http'):\n",
    "                    poem_url = 'https:'+ poem_url\n",
    "                \n",
    "                try:\n",
    "                    # Add delay between requests to be polite\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    # Get the poem page\n",
    "                    poem_response = requests.get(poem_url, headers=headers)\n",
    "                    poem_response.raise_for_status()\n",
    "                    \n",
    "                    # Parse the poem page\n",
    "                    poem_soup = BeautifulSoup(poem_response.text, 'html.parser')\n",
    "                    \n",
    "                    # Get poem title\n",
    "                    title = poem_soup.find('h1', class_='title-poem')\n",
    "                    title_text = title.text.strip() if title else \"Untitled\"\n",
    "                    \n",
    "                    # Get poem content\n",
    "                    poem_content = poem_soup.find('div', class_='poem-entry')\n",
    "                    poem_text = poem_content.text.strip() if poem_content else \"No content found\"\n",
    "                    \n",
    "                    # Write to file with formatting\n",
    "                    file.write(f\"{'='*50}\\n\")\n",
    "                    file.write(f\"Poem {i}: {title_text}\\n\")\n",
    "                    file.write(f\"{'='*50}\\n\\n\")\n",
    "                    file.write(poem_text + \"\\n\\n\\n\")\n",
    "                    \n",
    "                    print(f\"Successfully scraped: {title_text}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error scraping poem at {poem_url}: {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # urls=[\"https://mypoeticside.com/poets/charles-bukowski-poems\",\"https://mypoeticside.com/poets/william-shakespeare-poems\",\n",
    "#         #   \"https://mypoeticside.com/poets/sylvia-plath-poems\",\"https://mypoeticside.com/poets/john-milton-poems\",\"https://mypoeticside.com/poets/t-s-eliot-poems\",\"https://mypoeticside.com/poets/emily-dickinson-poems\"\n",
    "#         #   ,\"https://mypoeticside.com/poets/john-donne-poems\",\"https://mypoeticside.com/poets/alfred-lord-tennyson-poems\",\"https://mypoeticside.com/poets/rabindranath-tagore-poems\",\"https://mypoeticside.com/poets/rudyard-kipling-poems\"]\n",
    "#     urls=[\"https://mypoeticside.com/poets/rudyard-kipling-poems\"]\n",
    "#     for url in urls:  \n",
    "#         scrape_poems(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing all the alphabets\n",
    "import string\n",
    "char=[ i for i in string.ascii_lowercase]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped: 1887\n",
      "Successfully scraped: Along the field as we came by\n",
      "Successfully scraped: As Through the Wild Green Hills of Wyre\n",
      "Successfully scraped: As Through the Wild Green Hills of Wyre\n",
      "Successfully scraped: Be Still, My Soul, Be Still\n",
      "Successfully scraped: Bredon Hill\n",
      "Successfully scraped: Bring, In This Timeless Grave to Throw\n",
      "Successfully scraped: Could Man Be Drunk Forever\n",
      "Successfully scraped: Diffugere Nives\n",
      "Successfully scraped: Eight O'Clock\n",
      "Successfully scraped: Epitaph On An Army of Mercenaries\n",
      "Successfully scraped: Far In a Western Brookland\n",
      "Successfully scraped: Farewell to Barn and Stack and Tree\n",
      "Successfully scraped: Fragment of a Greek Tragedy\n",
      "Successfully scraped: From Far, From Eve and Morning\n",
      "Successfully scraped: Ho, everyone that thirsteth\n",
      "Successfully scraped: Hughley Steeple\n",
      "Successfully scraped: I Hoed and Trenched and Weeded\n",
      "Successfully scraped: If By Chance Your Eye Offend You\n",
      "Successfully scraped: If Truth in Hearts That Perish\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m     poets_list\u001b[38;5;241m.\u001b[39mextend(result)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m poet \u001b[38;5;129;01min\u001b[39;00m poets_list:\n\u001b[1;32m---> 57\u001b[0m     \u001b[43mscrape_poems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoet\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 46\u001b[0m, in \u001b[0;36mscrape_poems\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     43\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Get the poem page\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m poem_response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoem_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m poem_response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Parse the poem page\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    794\u001b[0m     conn,\n\u001b[0;32m    795\u001b[0m     method,\n\u001b[0;32m    796\u001b[0m     url,\n\u001b[0;32m    797\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    798\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    799\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    800\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    801\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    802\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    803\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    804\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1099\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:616\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    615\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m    618\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91978\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "\n",
    "def get_poets(url: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Scrapes poet links from the given URL.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to scrape poet links from\n",
    "        \n",
    "    Returns:\n",
    "        List[dict]: List of dictionaries containing poet names and their URLs\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Create BeautifulSoup object\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        poem_list = soup.find('ul', class_='list-poems')\n",
    "        if not poem_list:\n",
    "            return []\n",
    "            \n",
    "        poet_links = poem_list.find_all('a')\n",
    "        \n",
    "        # Extract poet information\n",
    "        poets = []\n",
    "        for link in poet_links:\n",
    "            poets.append({\n",
    "                'name': link.text.strip(),\n",
    "                'url': link['href']\n",
    "            })\n",
    "            \n",
    "        return poets\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching the URL: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing the content: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    poets_list=[]\n",
    "    for i in char:\n",
    "        result=get_poets(f\"https://mypoeticside.com/{i}-browse\")\n",
    "        poets_list.extend(result)\n",
    "    \n",
    "    for poet in poets_list:\n",
    "        scrape_poems(poet['url'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
